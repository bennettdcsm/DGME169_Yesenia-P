<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Fine-Tune Cell Annotation Tool – Project – Yesenia Puga</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header class="site-header">
    <div class="logo">
      <span class="logo-mark">YP</span>
      <span class="logo-text">Yesenia Puga</span>
      <span class="logo-subtitle">Embedded Systems & Robotics</span>
    </div>

    <nav class="main-nav">
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="projects.html" class="active">Projects</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="blog.html">News &amp; Blog</a></li>
        <li><a href="opportunities.html">Opportunities</a></li>
        <li><a href="contact.html" class="cta-link">Contact</a></li>
      </ul>
    </nav>
  </header>

  <main class="project-page">
    <section class="page-hero small">
      <h1>Fine-Tune Cell Annotation Tool</h1>
      <p>
        An interactive Python tool that lets researchers adjust model-generated
        neuron detections in real time using custom bounding boxes.
      </p>
    </section>

    <section class="section project-layout">
      <div class="project-main">
        <h2>Project Description</h2>
        <p>
          The Fine-Tune Cell Annotation Tool is a desktop application built in
          Python to help neuroscience labs review and correct model-generated
          detections in brain images. Instead of manually drawing every box from
          scratch, researchers can start from a model prediction and quickly
          adjust bounding boxes, delete false positives, and add missed cells.
        </p>
        <p>
          The tool loads large microscopy images, tiles them into smaller
          regions, and overlays the model’s bounding boxes. Users can then edit
          these boxes directly on the image and export corrected annotations for
          future model training and analysis.
        </p>

        <h2>Goals</h2>
        <ul>
          <li>Speed up the process of reviewing model predictions for cell detection.</li>
          <li>Make it easy for researchers to correct bounding boxes without coding.</li>
          <li>Keep all interaction inside a single, simple Python application.</li>
          <li>Create annotation files that can be used later for model fine-tuning.</li>
        </ul>

        <h2>Process</h2>
        <ol>
          <li>
            <strong>Image tiling and loading.</strong>
            I started by writing code to split large brain images into
            640 × 640 tiles so that they could be viewed and edited smoothly.
          </li>
          <li>
            <strong>Overlaying model predictions.</strong>
            I added logic to draw bounding boxes for each model detection on top
            of the image tiles, making sure coordinates stayed accurate after
            scaling and zooming.
          </li>
          <li>
            <strong>Interactive editing.</strong>
            I implemented tools to add, move, and delete boxes using mouse
            clicks and drags, with the coordinates updating in real time.
          </li>
          <li>
            <strong>Saving annotations.</strong>
            I created a simple export format that stores the final positions of
            all boxes so the data can be used to fine-tune the detection model
            later.
          </li>
          <li>
            <strong>Interface polish.</strong>
            I combined the image viewer and annotation controls into a single
            window so users can focus on the image while editing.
          </li>
        </ol>

        <h2>Tools Used</h2>
        <ul class="pill-list">
          <li>Python</li>
          <li>PyQt / GUI Toolkit</li>
          <li>NumPy</li>
          <li>OpenCV / Image Processing</li>
          <li>YOLO-based Model Outputs</li>
        </ul>

        <h2>Outcomes</h2>
        <p>
          The tool gives researchers a visual way to correct model mistakes
          without needing to write code. It turns long manual annotation
          sessions into a faster review and edit process. The corrected boxes
          are saved in a format that can be used for training and evaluation in
          future versions of the detection model.
        </p>
        <p>
          This project also helped me practice breaking a complex idea into
          smaller features: tiling images, drawing boxes, handling mouse events,
          and exporting clean data for machine learning workflows.
        </p>
      </div>

      <aside class="project-sidebar">
        <div class="image-placeholder tall">
          <p>Screenshot of Fine-Tune Tool UI<br>Placeholder</p>
        </div>
        <div class="image-placeholder">
          <p>Poster Figure or Diagram<br>Placeholder</p>
        </div>
        <a href="projects.html" class="btn secondary full-width">Back to Projects</a>
      </aside>
    </section>
  </main>

  <footer class="site-footer">
    <div class="footer-left">
      <p>&copy; 2025 Yesenia Puga. All rights reserved.</p>
    </div>
    <div class="footer-center">
      <a href="index.html">Home</a>
      <a href="projects.html">Projects</a>
      <a href="about.html">About</a>
      <a href="blog.html">Blog</a>
      <a href="contact.html">Contact</a>
    </div>
    <div class="footer-right">
      <a href="#" aria-label="LinkedIn">LI</a>
      <a href="#" aria-label="GitHub">GH</a>
    </div>
  </footer>
</body>
</html>